include required(classpath("application"))
backend {
  default = "pbs"
  providers {
    pbs {
      config {
        default-runtime-attributes {
          pbs_queue = "zeus_new_q"
        }
        filesystems {
          local {
            caching {
              duplication-strategy = [
                "soft-link"
                "hard-link"
                "copy"
              ]
              check-sibling-md5 = true
              hashing-strategy = "xxh64"
            }
            localization = [
              "soft-link"
              "hard-link"
              "copy"
            ]
          }
        }
        concurrent-job-limit = 1000
        script-epilogue = "sleep 5"
        runtime-attributes = """
## Caper custom attributes
# Environment choices = (docker, conda, singularity)
# If environment is not specified then prioritize docker > singularity > conda
# gpu is a plain string (to be able to specify gpu's name)
String? environment
String? conda
String? singularity
String? singularity_bindpath
String? gpu


Int cpu = 1
Int? time
Int? memory_mb


String? pbs_queue
String? pbs_extra_param
"""
        submit = """
cat << EOF > ${script}.caper
#!/bin/bash

if [ '${defined(environment)}' == 'true' ] && [ '${environment}' == 'singularity' ] || \
   [ '${defined(environment)}' == 'false' ] && [ '${defined(singularity)}' == 'true' ] && [ ! -z '${singularity}' ]
then
    mkdir -p $HOME/.singularity/lock/
    flock --exclusive --timeout 600 \
        $HOME/.singularity/lock/`echo -n '${singularity}' | md5sum | cut -d' ' -f1` \
        singularity exec --containall ${singularity} echo 'Successfully pulled ${singularity}'

    singularity exec --cleanenv --home=`dirname ${cwd}` \
        --bind=${singularity_bindpath}, \
        ${if defined(gpu) then ' --nv' else ''} \
        ${singularity} ${job_shell} ${script}

elif [ '${defined(environment)}' == 'true' ] && [ '${environment}' == 'conda' ] || \
     [ '${defined(environment)}' == 'false' ] && [ '${defined(conda)}' == 'true' ] && [ ! -z '${conda}' ]
then
    source /home/s.benjamin/other_software/conda/bin/activate ${conda}
    ${job_shell} ${script}
else
    ${job_shell} ${script}
fi

EOF

for ITER in 1 2 3; do
    qsub -l select=1:ncpus=${cpu} -N ${job_name} -o ${out} -e ${err} \
        ${'-q ' + pbs_queue} \
        ${pbs_extra_param} \
        ${script}.caper && break
    sleep 30
done
"""
        submit-docker = null
        kill-docker = null
        root = "/utemp/s.benjamin/cromwell-executions"
        check-alive = "qstat ${job_id}"
        kill = "qdel ${job_id}"
        job-id-regex = "([0-9]+)"
      }
      actor-factory = "cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"
    }
  }
}
webservice {}
services {
  LoadController {
    class = "cromwell.services.loadcontroller.impl.LoadControllerServiceActor"
    config {
      control-frequency = "21474834 seconds"
    }
  }
}
system {
  job-rate-control {
    jobs = 1
    per = "2 seconds"
  }
  abort-jobs-on-terminate = true
  graceful-server-shutdown = true
  max-concurrent-workflows = 40
}
call-caching {
  invalidate-bad-cache-results = true
  enabled = true
}
akka {
  http {
    server {
      request-timeout = "60 seconds"
    }
  }
}